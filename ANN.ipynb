{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "xgf3HnLMz77s"
   },
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import getopt\n",
    "import collections\n",
    "import tqdm\n",
    "import itertools\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from scipy import stats\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Qc9WnxVEli92",
    "outputId": "e1f2bcf7-472b-4880-f29f-535d668c654d"
   },
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('kaggle_train.csv')\n",
    "dataset_test = pd.read_csv('kaggle_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "4215gBDXlsUX",
    "outputId": "a3717cb6-0257-4f0e-f7d2-6c45bce99ba0"
   },
   "outputs": [],
   "source": [
    "x=dataset_train.loc[:,dataset_train.columns!='Labels']\n",
    "y = dataset_train['Labels']\n",
    "testing=dataset_test.drop([\"ID\"],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "X, y = evalml.demos.load_breast_cancer(data)\n",
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evalml\n",
      "  Using cached evalml-0.71.0-py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: black[jupyter]>=22.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (23.1.0)\n",
      "Requirement already satisfied: woodwork>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.22.0)\n",
      "Requirement already satisfied: vowpalwabbit>=8.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (9.8.0)\n",
      "Collecting catboost>=1.1.1\n",
      "  Using cached catboost-1.1.1-cp310-none-macosx_10_6_universal2.whl (22.0 MB)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.13.5)\n",
      "Requirement already satisfied: colorama>=0.4.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.4.6)\n",
      "Requirement already satisfied: shap>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.41.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (8.1.3)\n",
      "Collecting featuretools>=1.16.0\n",
      "  Using cached featuretools-1.23.0-py3-none-any.whl (555 kB)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.12.2)\n",
      "Requirement already satisfied: pmdarima>=1.8.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (2.0.3)\n",
      "Collecting category-encoders<=2.5.1.post0,>=2.2.2\n",
      "  Using cached category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: kaleido>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.2.1)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (1.2.2)\n",
      "Requirement already satisfied: graphviz>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.20.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (3.7.1)\n",
      "Collecting imbalanced-learn>=0.9.1\n",
      "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (5.13.1)\n",
      "Collecting nlp-primitives>=2.9.0\n",
      "  Using cached nlp_primitives-2.10.0-py3-none-any.whl (44.7 MB)\n",
      "Collecting lightgbm>=2.3.1\n",
      "  Using cached lightgbm-3.3.5.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging>=23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (23.0)\n",
      "Requirement already satisfied: networkx>=2.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (3.0)\n",
      "Requirement already satisfied: holidays<0.21,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.20)\n",
      "Requirement already satisfied: xgboost>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (1.7.4)\n",
      "Requirement already satisfied: scikit-optimize>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.9.0)\n",
      "Requirement already satisfied: pyzmq>=20.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (24.0.0)\n",
      "Requirement already satisfied: lime>=0.2.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.2.0.1)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (1.6.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (2.2.1)\n",
      "Requirement already satisfied: sktime>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (0.16.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (1.10.1)\n",
      "Requirement already satisfied: dask!=2022.10.1,>=2022.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (2023.3.1)\n",
      "Requirement already satisfied: ipywidgets>=7.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (8.0.2)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from evalml) (1.23.5)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from black[jupyter]>=22.3.0->evalml) (0.11.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from black[jupyter]>=22.3.0->evalml) (1.0.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from black[jupyter]>=22.3.0->evalml) (3.1.1)\n",
      "Requirement already satisfied: ipython>=7.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from black[jupyter]>=22.3.0->evalml) (8.5.0)\n",
      "Requirement already satisfied: tokenize-rt>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from black[jupyter]>=22.3.0->evalml) (5.0.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from catboost>=1.1.1->evalml) (1.16.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from category-encoders<=2.5.1.post0,>=2.2.2->evalml) (0.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dask!=2022.10.1,>=2022.2.0->evalml) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dask!=2022.10.1,>=2022.2.0->evalml) (0.12.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dask!=2022.10.1,>=2022.2.0->evalml) (1.3.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dask!=2022.10.1,>=2022.2.0->evalml) (2023.3.0)\n",
      "Collecting distributed!=2022.10.1,>=2022.2.0\n",
      "  Using cached distributed-2023.3.1-py3-none-any.whl (951 kB)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from featuretools>=1.16.0->evalml) (5.9.2)\n",
      "Requirement already satisfied: tqdm>=4.32.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from featuretools>=1.16.0->evalml) (4.65.0)\n",
      "Requirement already satisfied: PyMeeus in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from holidays<0.21,>=0.13->evalml) (0.5.12)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from holidays<0.21,>=0.13->evalml) (2.8.2)\n",
      "Requirement already satisfied: hijri-converter in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from holidays<0.21,>=0.13->evalml) (2.2.4)\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from holidays<0.21,>=0.13->evalml) (2.4.0)\n",
      "Requirement already satisfied: korean-lunar-calendar in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from holidays<0.21,>=0.13->evalml) (0.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imbalanced-learn>=0.9.1->evalml) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imbalanced-learn>=0.9.1->evalml) (1.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipywidgets>=7.5->evalml) (3.0.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipywidgets>=7.5->evalml) (5.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipywidgets>=7.5->evalml) (6.15.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipywidgets>=7.5->evalml) (4.0.3)\n",
      "Requirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lightgbm>=2.3.1->evalml) (0.40.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lime>=0.2.0.1->evalml) (0.20.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.3->evalml) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.3->evalml) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.3->evalml) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.3->evalml) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.3->evalml) (4.39.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.3->evalml) (9.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk>=3.4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nlp-primitives>=2.9.0->evalml) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.5.0->evalml) (2022.7.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly>=5.0.0->evalml) (8.2.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pmdarima>=1.8.5->evalml) (0.29.33)\n",
      "Requirement already satisfied: urllib3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pmdarima>=1.8.5->evalml) (1.26.15)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pmdarima>=1.8.5->evalml) (63.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-optimize>=0.9.0->evalml) (21.10.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap>=0.40.0->evalml) (0.0.7)\n",
      "Requirement already satisfied: numba in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap>=0.40.0->evalml) (0.56.4)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sktime>=0.15.0->evalml) (1.2.13)\n",
      "Requirement already satisfied: importlib-resources>=5.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from woodwork>=0.22.0->evalml) (5.12.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deprecated>=1.2.13->sktime>=0.15.0->evalml) (1.15.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (1.0.5)\n",
      "Requirement already satisfied: locket>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (1.0.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (1.7.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (2.4.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (3.1.2)\n",
      "Requirement already satisfied: zict>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (2.2.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (6.2)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (1.5.5)\n",
      "Requirement already satisfied: debugpy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (1.6.3)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (7.3.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (2.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (4.8.0)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.5.0)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (3.0.31)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk>=3.4.5->nlp-primitives>=2.9.0->evalml) (2022.10.31)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from numba->shap>=0.40.0->evalml) (0.39.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (2.26.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (0.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (2023.3.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (2.1.1)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (4.11.1)\n",
      "Requirement already satisfied: entrypoints in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (0.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.2.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: heapdict in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from zict>=2.1.0->distributed!=2022.10.1,>=2022.2.0->featuretools>=1.16.0->evalml) (1.0.1)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (2.0.8)\n",
      "Requirement already satisfied: executing in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]>=22.3.0->evalml) (1.0.0)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[86 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/dask.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing lightgbm.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to lightgbm.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching 'build'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.so' under directory 'compile'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:wheel:installing to build/bdist.macosx-10.9-universal2/wheel\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile the library.\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile with CMake.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 95, in silent_call\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd, stderr=log, stdout=log)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 364, in check_call\n",
      "  \u001b[31m   \u001b[0m     retcode = call(*popenargs, **kwargs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 345, in call\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as p:\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 969, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 1845, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 334, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='lightgbm',\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 177, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 193, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 378, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"install\")\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 317, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 248, in run\n",
      "  \u001b[31m   \u001b[0m     compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu, use_cuda=self.cuda, use_mpi=self.mpi,\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 198, in compile_cpp\n",
      "  \u001b[31m   \u001b[0m     silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake and all required dependencies first')\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 99, in silent_call\n",
      "  \u001b[31m   \u001b[0m     raise Exception(\"\\n\".join((error_msg, LOG_NOTICE)))\n",
      "  \u001b[31m   \u001b[0m Exception: Please install CMake and all required dependencies first\n",
      "  \u001b[31m   \u001b[0m The full version of error log was saved into /Users/anandr/LightGBM_compilation.log\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build lightgbm\n",
      "Installing collected packages: lightgbm, imbalanced-learn, distributed, catboost, category-encoders, featuretools, nlp-primitives, evalml\n",
      "  Running setup.py install for lightgbm ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for lightgbm\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile the library.\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile with CMake.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 95, in silent_call\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd, stderr=log, stdout=log)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 364, in check_call\n",
      "  \u001b[31m   \u001b[0m     retcode = call(*popenargs, **kwargs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 345, in call\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as p:\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 969, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 1845, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 334, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='lightgbm',\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 177, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 193, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 248, in run\n",
      "  \u001b[31m   \u001b[0m     compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu, use_cuda=self.cuda, use_mpi=self.mpi,\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 198, in compile_cpp\n",
      "  \u001b[31m   \u001b[0m     silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake and all required dependencies first')\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-feung2r7/lightgbm_a6ee56da4a694740a5408970edc9fb25/setup.py\", line 99, in silent_call\n",
      "  \u001b[31m   \u001b[0m     raise Exception(\"\\n\".join((error_msg, LOG_NOTICE)))\n",
      "  \u001b[31m   \u001b[0m Exception: Please install CMake and all required dependencies first\n",
      "  \u001b[31m   \u001b[0m The full version of error log was saved into /Users/anandr/LightGBM_compilation.log\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m lightgbm\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    " !pip install evalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainig_dataset(df3)_devided_into_80%_&_20%\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "x_valid.reset_index(inplace=True, drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 150, 'random_state': 42}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [108], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the best model on the test data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m best_clf \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m---> 28\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m best_clf\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mx_test\u001b[49m)[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# predicted probabilities for the positive class\u001b[39;00m\n\u001b[1;32m     29\u001b[0m auroc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_valid, y_pred_proba)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC on test data: \u001b[39m\u001b[38;5;124m\"\u001b[39m, auroc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150,500,1000,1500,2000, 3000,4000,5000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,42]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred_proba = best_clf.predict_proba(x_valid)[:, 1]  # predicted probabilities for the positive class\n",
    "auroc = roc_auc_score(y_valid, y_pred_proba)\n",
    "print(\"AUROC on test data: \", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of the columns on the basis of mean and standard deviation ((x-u)/s)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "#PCA(reduce dimention of feture)\n",
    "#Imputer(handel nan values)\n",
    "\n",
    "#for train use fit.transform function\n",
    "#x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "#x1.columns=x.columns\n",
    "#x1\n",
    "#for test data just .transform function\n",
    "#x_test_scaled=pd.DataFrame(scaler.transform(x_test)\n",
    "x_valid_scaled = pd.DataFrame(scaler.transform(x_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "GradientBoostingClassifier(random_state=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.575250</td>\n",
       "      <td>0.567317</td>\n",
       "      <td>0.138041</td>\n",
       "      <td>0.552546</td>\n",
       "      <td>0.626476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.563665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>0.592260</td>\n",
       "      <td>0.581829</td>\n",
       "      <td>0.164582</td>\n",
       "      <td>0.547655</td>\n",
       "      <td>0.606738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.165368</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.621118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TP    FP    FN    TN      SENS      SPEC      PREC       ACC       MCC  \\\n",
       "0  10.8   8.2   9.2  12.0  0.540000  0.595238  0.575250  0.567317  0.138041   \n",
       "1  16.0  12.0  12.0  11.0  0.571429  0.478261  0.571429  0.529412  0.049689   \n",
       "2  10.2   7.0   9.8  13.2  0.510000  0.652857  0.592260  0.581829  0.164582   \n",
       "3  18.0  11.0  10.0  12.0  0.642857  0.521739  0.620690  0.588235  0.165368   \n",
       "\n",
       "         F1       AUC  \n",
       "0  0.552546  0.626476  \n",
       "1  0.571429  0.563665  \n",
       "2  0.547655  0.606738  \n",
       "3  0.631579  0.621118  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_list = [xgboost.XGBClassifier(random_state=1, n_jobs= -1), \n",
    "                                         GradientBoostingClassifier(random_state=3)]\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train_scaled, y_train):\n",
    "        train_x = x_train_scaled.iloc[train,:]\n",
    "        test_x = x_train_scaled.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean())\n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_valid_scaled)[:,1]\n",
    "    predict_label_y = clf.predict(x_valid_scaled)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 150, 'random_state': 42}\n",
      "AUROC on test data:  0.610248447204969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150,500,1000,1500,2000, 3000,4000,5000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,42]\n",
    "}\n",
    "\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred_proba = best_clf.predict_proba(x_valid_scaled)[:, 1]  # predicted probabilities for the positive class\n",
    "auroc = roc_auc_score(y_valid, y_pred_proba)\n",
    "print(\"AUROC on test data: \", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#model = LogisticRegression(solver='liblinear')\n",
    "#model = RandomForestRegressor( n_jobs=-1)\n",
    "#model = SVR(kernel='linear')\n",
    "#model = KNeighborsRegressor()\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=model, n_features_to_select=100, verbose=2)\n",
    "sf = rfe.fit(x_train_scaled, y_train)  # It learns relationship and transfrom the data\n",
    "sc = x_train_scaled.columns[rfe.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "x2_rfe50=x_train_scaled[sc] #This will show the first few rows of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_rfe50=x_valid_scaled[sc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_metrics(cf_matrix):\n",
    "  tn = cf_matrix[0]\n",
    "  fp = cf_matrix[1]\n",
    "  fn = cf_matrix[2]\n",
    "  tp = cf_matrix[3]\n",
    "  if (((tp+fn)==0)|((tn+fp)==0)|((tp+fp)==0)|((tn+fp)==0)|((tn+fn)==0)):\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = 0\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = 0\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "  else: \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5)\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=50, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "GradientBoostingClassifier(max_depth=50, random_state=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.622381</td>\n",
       "      <td>0.627494</td>\n",
       "      <td>0.626341</td>\n",
       "      <td>0.252727</td>\n",
       "      <td>0.628258</td>\n",
       "      <td>0.695357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.128882</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.531056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.544762</td>\n",
       "      <td>0.539706</td>\n",
       "      <td>0.537317</td>\n",
       "      <td>0.074633</td>\n",
       "      <td>0.533535</td>\n",
       "      <td>0.529298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.085804</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.580745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TP    FP    FN    TN      SENS      SPEC      PREC       ACC       MCC  \\\n",
       "0  12.6   7.6   7.4  12.6  0.630000  0.622381  0.627494  0.626341  0.252727   \n",
       "1  17.0  11.0  11.0  12.0  0.607143  0.521739  0.607143  0.568627  0.128882   \n",
       "2  10.6   9.2   9.4  11.0  0.530000  0.544762  0.539706  0.537317  0.074633   \n",
       "3  17.0  12.0  11.0  11.0  0.607143  0.478261  0.586207  0.549020  0.085804   \n",
       "\n",
       "         F1       AUC  \n",
       "0  0.628258  0.695357  \n",
       "1  0.607143  0.531056  \n",
       "2  0.533535  0.529298  \n",
       "3  0.596491  0.580745  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_list = [xgboost.XGBClassifier(random_state=1, n_jobs= -1, n_estimators=100, max_depth=50), \n",
    "                   GradientBoostingClassifier(random_state=3, n_estimators=100,max_depth=50 )]\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x2_rfe50, y_train):\n",
    "        train_x = x2_rfe50.iloc[train,:]\n",
    "        test_x = x2_rfe50.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean())\n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(test_x_rfe50)[:,1]\n",
    "    predict_label_y = clf.predict(test_x_rfe50)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 1.0, 'max_depth': 1, 'n_estimators': 500, 'random_state': 1}\n",
      "AUROC on test data:  0.59472049689441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150,500,1000,1500,2000, 3000,4000,5000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,42]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x2_rfe50, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred_proba = best_clf.predict_proba(test_x_rfe50)[:, 1]  # predicted probabilities for the positive class\n",
    "auroc = roc_auc_score(y_valid, y_pred_proba)\n",
    "print(\"AUROC on test data: \", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yYW1mOSaKb6m",
    "outputId": "1c94b59c-17fa-420e-b7f8-b5a4a00a148e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [201, 252]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gb \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe feature importances of GBDT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(gb\u001b[38;5;241m.\u001b[39mfeature_importances_)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:429\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_state()\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# Check input\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# Since check_array converts both X and y to the same dtype, but the\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# trees use different types for X and y, checking them separately.\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    431\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m sample_weight_is_none \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    435\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [201, 252]"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=20)\n",
    "gb.fit(x_train, y)\n",
    "print(\"The feature importances of GBDT\")\n",
    "print(gb.feature_importances_)\n",
    "\n",
    "model = fs.SelectFromModel(gb, prefit=True)\n",
    "x1 = model.transform(x_valid)\n",
    "q = model.transform(q)\n",
    "q=pd.DataFrame(q)\n",
    "x1=pd.DataFrame(x1)\n",
    "x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "FV-Wjd0-NPb6",
    "outputId": "a18dea58-5395-4102-8163-39351a30f62b"
   },
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuG7jQvSPzr8",
    "outputId": "6a2b7bad-d976-443a-ffa9-70936c5e7bbc"
   },
   "outputs": [],
   "source": [
    "cat_features = list(range(0, x1.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMGXi-3im1hT"
   },
   "outputs": [],
   "source": [
    "x1_train,x1_test,y_train,y_test=train_test_split(x1,y,test_size=20,random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wd5ShfVcM-no"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x1_train = sc.fit_transform(x1_train)\n",
    "q= sc.fit_transform(q)\n",
    "x1_test = sc.transform(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9rfUOFCm5CS",
    "outputId": "f9454656-609b-4aca-f061-0163de79d05d"
   },
   "outputs": [],
   "source": [
    "x1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoHiCTI9m8Pr",
    "outputId": "9476b313-2244-4117-a0f9-d7f989bc7489"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55485615, -0.64923035,  0.93723706, ..., -0.60379483,\n",
       "         0.70627326,  0.50265944],\n",
       "       [ 0.37864337,  0.09981104,  0.88383112, ..., -0.15461728,\n",
       "        -0.36932868, -0.60604781],\n",
       "       [ 0.04069516, -1.26538023, -0.74352004, ...,  0.12926729,\n",
       "         0.24559245, -0.21545859],\n",
       "       ...,\n",
       "       [ 0.98562688, -0.89433876, -0.37190596, ..., -0.77503135,\n",
       "        -0.07525951, -1.01077451],\n",
       "       [-0.16255584, -0.28378377,  1.04439522, ...,  2.26178503,\n",
       "        -0.55867347, -0.64368859],\n",
       "       [-0.63366646, -0.22367405,  0.94330804, ..., -0.41242893,\n",
       "        -0.33344867, -1.26063506]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6wnSCwDm_Mt",
    "outputId": "59fa526c-132b-4f59-e3bd-dcae2361347b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43     0\n",
       "194    1\n",
       "96     0\n",
       "247    1\n",
       "48     0\n",
       "      ..\n",
       "186    0\n",
       "116    1\n",
       "40     0\n",
       "69     1\n",
       "189    1\n",
       "Name: Labels, Length: 232, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejhrPRkxnB_P",
    "outputId": "9c037ac9-0d08-4741-b707-587301826bc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199    1\n",
       "231    1\n",
       "12     0\n",
       "36     0\n",
       "5      1\n",
       "51     1\n",
       "17     1\n",
       "19     1\n",
       "90     0\n",
       "217    0\n",
       "190    1\n",
       "71     1\n",
       "26     1\n",
       "108    1\n",
       "9      1\n",
       "52     0\n",
       "246    1\n",
       "89     1\n",
       "167    1\n",
       "126    1\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3m1zR3iWbAcM"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YFRIvVDibLzJ"
   },
   "outputs": [],
   "source": [
    "dt = RandomForestClassifier(max_depth=10,n_estimators=1000, random_state=0,bootstrap= [True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "clJjCTHebOlg"
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'bootstrap' parameter of RandomForestClassifier must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got [True] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:340\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    Build a forest of trees from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'bootstrap' parameter of RandomForestClassifier must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got [True] instead."
     ]
    }
   ],
   "source": [
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2sRsPZvbRb2"
   },
   "outputs": [],
   "source": [
    "dt.score(x1_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dHkGOruObXiu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = dt.predict(q)\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test['Labels'] = y_pred_1.tolist()\n",
    "dataset_test[['ID','Labels']].to_csv(\"submission_ann.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "196    1\n",
       "197    0\n",
       "198    0\n",
       "199    0\n",
       "200    1\n",
       "Name: Labels, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "5eX69LfwtF5h",
    "outputId": "7f0fd94a-9b6d-45f4-cf35-349989f0d654",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-macos (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-macos\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-macos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zNvjpEfRulL4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initializing the ANN\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ann \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Initializing the ANN\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJEI8px8uqvo"
   },
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_TIgVLvuwiP"
   },
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxQ3gPW0u2S6"
   },
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEaAGQj1u7lz"
   },
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMbdKEcXvCyK",
    "outputId": "06363af7-8e50-4934-9496-7e24e876ac52"
   },
   "outputs": [],
   "source": [
    " #Training the ANN on the Training set\n",
    "ann.fit(x1_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRtFYMWGvd4O",
    "outputId": "8bf15c61-0174-4bd2-becd-b1a077145145"
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = ann.predict(x1_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHbj7rHsv6DO",
    "outputId": "b837f846-14d5-4350-a797-60e119711b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  2]\n",
      " [ 4 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgfeQ-D_Sf0A",
    "outputId": "1c1b4f29-aa6d-4d67-cba7-9faf40c063f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = ann.predict(q)\n",
    "y_pred_1 = y_pred_1 > 0.5\n",
    "y_pred_1=1*y_pred_1\n",
    "y_pred_1 = np.squeeze(y_pred_1)\n",
    "\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlwsZQHfrADS"
   },
   "outputs": [],
   "source": [
    "dataset_test['Labels'] = y_pred_1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daczgXDkrGoX"
   },
   "outputs": [],
   "source": [
    "dataset_test['Labels'] = y_pred_1.tolist()\n",
    "dataset_test[['ID','Labels']].to_csv(\"submission_ann.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ol_QndjrOY6"
   },
   "outputs": [],
   "source": [
    "dataset3=pd.read_csv(\"submission_ann.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "fL_UnK4arVrR",
    "outputId": "3b379aa7-7289-4ff4-fa14-ec4081c458c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5ebbb063-e7a8-47e9-966f-e1f3f174e3fa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ebbb063-e7a8-47e9-966f-e1f3f174e3fa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5ebbb063-e7a8-47e9-966f-e1f3f174e3fa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5ebbb063-e7a8-47e9-966f-e1f3f174e3fa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       ID  Labels\n",
       "0    1001       0\n",
       "1    1002       1\n",
       "2    1003       1\n",
       "3    1004       0\n",
       "4    1005       1\n",
       "..    ...     ...\n",
       "99   1100       0\n",
       "100  1101       0\n",
       "101  1102       1\n",
       "102  1103       1\n",
       "103  1104       0\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
