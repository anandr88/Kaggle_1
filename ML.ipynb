{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd34ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import getopt\n",
    "import collections\n",
    "import tqdm\n",
    "import itertools\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from scipy import stats\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce794e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b09a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file read\n",
    "\n",
    "\n",
    "test= pd.read_csv(\"test_data.csv\")\n",
    "train= pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "test = test.sample(frac=1, random_state=42)  # set random_state for r\n",
    "train = train.sample(frac=1, random_state=42)  # set random_state for r\n",
    "\n",
    "x_train = train.drop(columns=['Label'])\n",
    "y_train = train.Label\n",
    "x_valid = test.drop(columns=['Label'])\n",
    "y_valid = test.Label\n",
    "\n",
    "x_valid.reset_index(inplace=True, drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)\n",
    "\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "x_train = x_train.drop(columns=['Unnamed: 0'])\n",
    "x_valid = x_valid.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61571c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAC_A</th>\n",
       "      <th>AAC_C</th>\n",
       "      <th>AAC_D</th>\n",
       "      <th>AAC_E</th>\n",
       "      <th>AAC_F</th>\n",
       "      <th>AAC_G</th>\n",
       "      <th>AAC_H</th>\n",
       "      <th>AAC_I</th>\n",
       "      <th>AAC_K</th>\n",
       "      <th>AAC_L</th>\n",
       "      <th>...</th>\n",
       "      <th>DPC1_YM</th>\n",
       "      <th>DPC1_YN</th>\n",
       "      <th>DPC1_YP</th>\n",
       "      <th>DPC1_YQ</th>\n",
       "      <th>DPC1_YR</th>\n",
       "      <th>DPC1_YS</th>\n",
       "      <th>DPC1_YT</th>\n",
       "      <th>DPC1_YV</th>\n",
       "      <th>DPC1_YW</th>\n",
       "      <th>DPC1_YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.11</td>\n",
       "      <td>5.56</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.56</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.04</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.08</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>12.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>26.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>18.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.17</td>\n",
       "      <td>8.33</td>\n",
       "      <td>4.17</td>\n",
       "      <td>12.50</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6714 rows Ã— 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAC_A  AAC_C  AAC_D  AAC_E  AAC_F  AAC_G  AAC_H  AAC_I  AAC_K  AAC_L  \\\n",
       "0     11.11   5.56  11.11  11.11   5.56   5.56   0.00   0.00   0.00   5.56   \n",
       "1      0.00   6.67   0.00  13.33   0.00   0.00   0.00   0.00   0.00   6.67   \n",
       "2     21.74   0.00   0.00  13.04   8.70   8.70   0.00   8.70   4.35   4.35   \n",
       "3      9.09   0.00   0.00   9.09   9.09   0.00   9.09   0.00   9.09   0.00   \n",
       "4      7.69   0.00   0.00  23.08   7.69   0.00   0.00   7.69   7.69   0.00   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "6709   6.25   0.00   6.25  12.50   6.25  12.50   0.00   6.25   0.00   0.00   \n",
       "6710  26.67   0.00   6.67  20.00   0.00   0.00   0.00  13.33  20.00   0.00   \n",
       "6711  13.33   0.00   0.00  20.00   0.00   0.00   0.00   0.00   0.00   6.67   \n",
       "6712  18.18   0.00   0.00   0.00   0.00  18.18   0.00   9.09   9.09   0.00   \n",
       "6713   4.17   0.00  16.67   0.00   4.17   8.33   4.17  12.50   4.17   4.17   \n",
       "\n",
       "      ...  DPC1_YM  DPC1_YN  DPC1_YP  DPC1_YQ  DPC1_YR  DPC1_YS  DPC1_YT  \\\n",
       "0     ...      0.0      0.0     5.88      0.0      0.0      0.0     0.00   \n",
       "1     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "2     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "3     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "4     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "...   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "6709  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "6710  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "6711  ...      0.0      0.0     0.00      0.0      0.0      0.0     7.14   \n",
       "6712  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "6713  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "\n",
       "      DPC1_YV  DPC1_YW  DPC1_YY  \n",
       "0        0.00      0.0     0.00  \n",
       "1        0.00      0.0     0.00  \n",
       "2        0.00      0.0     0.00  \n",
       "3        0.00      0.0     0.00  \n",
       "4        0.00      0.0     0.00  \n",
       "...       ...      ...      ...  \n",
       "6709     6.67      0.0     6.67  \n",
       "6710     0.00      0.0     0.00  \n",
       "6711     0.00      0.0     7.14  \n",
       "6712     0.00      0.0     0.00  \n",
       "6713     0.00      0.0     0.00  \n",
       "\n",
       "[6714 rows x 420 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc051cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 420)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8525ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#model = LogisticRegression(solver='liblinear')\n",
    "#model = RandomForestRegressor( n_jobs=-1)\n",
    "#model = SVR(kernel='linear')\n",
    "#model = KNeighborsRegressor()\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=model, verbose=2)\n",
    "sf = rfe.fit(x_train, y_train)  # It learns relationship and transfrom the data\n",
    "sc = x_train.columns[rfe.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "x2_rfe50=x_train[sc] #This will show the first few rows of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e833724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.11,  5.56, 11.11, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  6.67,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [21.74,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [13.33,  0.  ,  0.  , ...,  0.  ,  0.  ,  7.14],\n",
       "       [18.18,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 4.17,  0.  , 16.67, ...,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fa5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=1)\n",
    "X_train = selector.fit_transform(np.array(x_train))\n",
    "x_test = selector.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689e00c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 284)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56c35c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = [ RandomForestClassifier(random_state=1, n_jobs= -1),\n",
    "                   ExtraTreesClassifier(random_state=1, n_jobs= -1), MLPClassifier(random_state=1),\n",
    "                   GradientBoostingClassifier(random_state=1),DecisionTreeClassifier(random_state=1), \n",
    "                   LogisticRegression(random_state=0, n_jobs= -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d98dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1, random_state=1)\n",
      "ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n",
      "DecisionTreeClassifier(random_state=1)\n",
      "LogisticRegression(n_jobs=-1, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534.0</td>\n",
       "      <td>135.4</td>\n",
       "      <td>125.8</td>\n",
       "      <td>547.6</td>\n",
       "      <td>0.809336</td>\n",
       "      <td>0.801757</td>\n",
       "      <td>0.798084</td>\n",
       "      <td>0.805481</td>\n",
       "      <td>0.611191</td>\n",
       "      <td>0.803548</td>\n",
       "      <td>0.903714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>659.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>0.798788</td>\n",
       "      <td>0.823185</td>\n",
       "      <td>0.813580</td>\n",
       "      <td>0.811197</td>\n",
       "      <td>0.622264</td>\n",
       "      <td>0.806116</td>\n",
       "      <td>0.909490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>530.0</td>\n",
       "      <td>126.6</td>\n",
       "      <td>129.8</td>\n",
       "      <td>556.4</td>\n",
       "      <td>0.803272</td>\n",
       "      <td>0.814641</td>\n",
       "      <td>0.807571</td>\n",
       "      <td>0.809054</td>\n",
       "      <td>0.618114</td>\n",
       "      <td>0.805327</td>\n",
       "      <td>0.905635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>0.807273</td>\n",
       "      <td>0.838407</td>\n",
       "      <td>0.828358</td>\n",
       "      <td>0.823109</td>\n",
       "      <td>0.646162</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.912878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501.6</td>\n",
       "      <td>149.0</td>\n",
       "      <td>158.2</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.760230</td>\n",
       "      <td>0.781845</td>\n",
       "      <td>0.771343</td>\n",
       "      <td>0.771224</td>\n",
       "      <td>0.542467</td>\n",
       "      <td>0.765594</td>\n",
       "      <td>0.849564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>632.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>0.766061</td>\n",
       "      <td>0.799766</td>\n",
       "      <td>0.787049</td>\n",
       "      <td>0.783204</td>\n",
       "      <td>0.566277</td>\n",
       "      <td>0.776413</td>\n",
       "      <td>0.861703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>470.0</td>\n",
       "      <td>169.4</td>\n",
       "      <td>189.8</td>\n",
       "      <td>513.6</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.751977</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.732497</td>\n",
       "      <td>0.464906</td>\n",
       "      <td>0.723603</td>\n",
       "      <td>0.808109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>584.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.707879</td>\n",
       "      <td>0.743560</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.451798</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>0.807122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>488.8</td>\n",
       "      <td>169.6</td>\n",
       "      <td>171.0</td>\n",
       "      <td>513.4</td>\n",
       "      <td>0.740828</td>\n",
       "      <td>0.751684</td>\n",
       "      <td>0.742974</td>\n",
       "      <td>0.746351</td>\n",
       "      <td>0.492725</td>\n",
       "      <td>0.741761</td>\n",
       "      <td>0.746256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>601.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0.728485</td>\n",
       "      <td>0.738876</td>\n",
       "      <td>0.729369</td>\n",
       "      <td>0.733770</td>\n",
       "      <td>0.467371</td>\n",
       "      <td>0.728927</td>\n",
       "      <td>0.733680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>438.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>221.8</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.663846</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.663709</td>\n",
       "      <td>0.669498</td>\n",
       "      <td>0.338876</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>0.734304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>535.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.645356</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.304201</td>\n",
       "      <td>0.646917</td>\n",
       "      <td>0.718747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TP     FP     FN     TN      SENS      SPEC      PREC       ACC  \\\n",
       "0   534.0  135.4  125.8  547.6  0.809336  0.801757  0.798084  0.805481   \n",
       "1   659.0  151.0  166.0  703.0  0.798788  0.823185  0.813580  0.811197   \n",
       "2   530.0  126.6  129.8  556.4  0.803272  0.814641  0.807571  0.809054   \n",
       "3   666.0  138.0  159.0  716.0  0.807273  0.838407  0.828358  0.823109   \n",
       "4   501.6  149.0  158.2  534.0  0.760230  0.781845  0.771343  0.771224   \n",
       "5   632.0  171.0  193.0  683.0  0.766061  0.799766  0.787049  0.783204   \n",
       "6   470.0  169.4  189.8  513.6  0.712335  0.751977  0.735437  0.732497   \n",
       "7   584.0  219.0  241.0  635.0  0.707879  0.743560  0.727273  0.726027   \n",
       "8   488.8  169.6  171.0  513.4  0.740828  0.751684  0.742974  0.746351   \n",
       "9   601.0  223.0  224.0  631.0  0.728485  0.738876  0.729369  0.733770   \n",
       "10  438.0  222.0  221.8  461.0  0.663846  0.674963  0.663709  0.669498   \n",
       "11  535.0  294.0  290.0  560.0  0.648485  0.655738  0.645356  0.652174   \n",
       "\n",
       "         MCC        F1       AUC  \n",
       "0   0.611191  0.803548  0.903714  \n",
       "1   0.622264  0.806116  0.909490  \n",
       "2   0.618114  0.805327  0.905635  \n",
       "3   0.646162  0.817680  0.912878  \n",
       "4   0.542467  0.765594  0.849564  \n",
       "5   0.566277  0.776413  0.861703  \n",
       "6   0.464906  0.723603  0.808109  \n",
       "7   0.451798  0.717445  0.807122  \n",
       "8   0.492725  0.741761  0.746256  \n",
       "9   0.467371  0.728927  0.733680  \n",
       "10  0.338876  0.663710  0.734304  \n",
       "11  0.304201  0.646917  0.718747  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "def calc_metrics(cf_matrix):\n",
    "  tn = cf_matrix[0]\n",
    "  fp = cf_matrix[1]\n",
    "  fn = cf_matrix[2]\n",
    "  tp = cf_matrix[3]\n",
    "  if (((tp+fn)==0)|((tn+fp)==0)|((tp+fp)==0)|((tn+fp)==0)|((tn+fn)==0)):\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = 0\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = 0\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "  else: \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5)\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train, y_train):\n",
    "        train_x = x_train.iloc[train,:]\n",
    "        test_x = x_train.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_valid)[:,1]\n",
    "    predict_label_y = clf.predict(x_valid)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c12772e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.648700</td>\n",
       "      <td>0.788975</td>\n",
       "      <td>0.766665</td>\n",
       "      <td>0.517128</td>\n",
       "      <td>0.345650</td>\n",
       "      <td>-0.187092</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.893372</td>\n",
       "      <td>-0.266024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>5.471057</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.912707</td>\n",
       "      <td>1.043471</td>\n",
       "      <td>-0.939546</td>\n",
       "      <td>0.818786</td>\n",
       "      <td>-0.759387</td>\n",
       "      <td>-0.876669</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.893372</td>\n",
       "      <td>-0.114759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.142648</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.939546</td>\n",
       "      <td>0.779380</td>\n",
       "      <td>0.969717</td>\n",
       "      <td>0.202345</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>0.583114</td>\n",
       "      <td>-0.276775</td>\n",
       "      <td>-0.430916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.364808</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.939546</td>\n",
       "      <td>0.242646</td>\n",
       "      <td>1.047229</td>\n",
       "      <td>-0.876669</td>\n",
       "      <td>1.732081</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>0.395103</td>\n",
       "      <td>-1.023711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168051</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.939546</td>\n",
       "      <td>2.143635</td>\n",
       "      <td>0.768982</td>\n",
       "      <td>-0.876669</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>0.410984</td>\n",
       "      <td>0.196658</td>\n",
       "      <td>-1.023711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>-0.034328</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.020294</td>\n",
       "      <td>0.706004</td>\n",
       "      <td>0.482785</td>\n",
       "      <td>0.673638</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>0.165571</td>\n",
       "      <td>-0.893372</td>\n",
       "      <td>-1.023711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>5.913007</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>5.882654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>2.835514</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>1.725119</td>\n",
       "      <td>-0.759387</td>\n",
       "      <td>-0.876669</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>1.372187</td>\n",
       "      <td>1.941557</td>\n",
       "      <td>-1.023711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>0.960701</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.939546</td>\n",
       "      <td>1.725119</td>\n",
       "      <td>-0.759387</td>\n",
       "      <td>-0.876669</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.893372</td>\n",
       "      <td>-0.114759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>5.947974</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>6.307612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>1.642323</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.939546</td>\n",
       "      <td>-0.992521</td>\n",
       "      <td>-0.759387</td>\n",
       "      <td>1.378098</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>0.649581</td>\n",
       "      <td>0.395103</td>\n",
       "      <td>-1.023711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>-0.326652</td>\n",
       "      <td>-0.485799</td>\n",
       "      <td>1.620538</td>\n",
       "      <td>-0.992521</td>\n",
       "      <td>0.069390</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>0.486140</td>\n",
       "      <td>1.230733</td>\n",
       "      <td>-0.302289</td>\n",
       "      <td>-0.455446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.183593</td>\n",
       "      <td>-0.151182</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.177542</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.169234</td>\n",
       "      <td>-0.086772</td>\n",
       "      <td>-0.148134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6714 rows Ã— 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.648700  0.788975  0.766665  0.517128  0.345650 -0.187092 -0.569871   \n",
       "1    -0.912707  1.043471 -0.939546  0.818786 -0.759387 -0.876669 -0.569871   \n",
       "2     2.142648 -0.485799 -0.939546  0.779380  0.969717  0.202345 -0.569871   \n",
       "3     0.364808 -0.485799 -0.939546  0.242646  1.047229 -0.876669  1.732081   \n",
       "4     0.168051 -0.485799 -0.939546  2.143635  0.768982 -0.876669 -0.569871   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6709 -0.034328 -0.485799  0.020294  0.706004  0.482785  0.673638 -0.569871   \n",
       "6710  2.835514 -0.485799  0.084795  1.725119 -0.759387 -0.876669 -0.569871   \n",
       "6711  0.960701 -0.485799 -0.939546  1.725119 -0.759387 -0.876669 -0.569871   \n",
       "6712  1.642323 -0.485799 -0.939546 -0.992521 -0.759387  1.378098 -0.569871   \n",
       "6713 -0.326652 -0.485799  1.620538 -0.992521  0.069390  0.156456  0.486140   \n",
       "\n",
       "           7         8         9    ...       410       411       412  \\\n",
       "0    -0.899591 -0.893372 -0.266024  ... -0.092033 -0.183593  5.471057   \n",
       "1    -0.899591 -0.893372 -0.114759  ... -0.092033 -0.183593 -0.151182   \n",
       "2     0.583114 -0.276775 -0.430916  ... -0.092033 -0.183593 -0.151182   \n",
       "3    -0.899591  0.395103 -1.023711  ... -0.092033 -0.183593 -0.151182   \n",
       "4     0.410984  0.196658 -1.023711  ... -0.092033 -0.183593 -0.151182   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6709  0.165571 -0.893372 -1.023711  ... -0.092033 -0.183593 -0.151182   \n",
       "6710  1.372187  1.941557 -1.023711  ... -0.092033 -0.183593 -0.151182   \n",
       "6711 -0.899591 -0.893372 -0.114759  ... -0.092033 -0.183593 -0.151182   \n",
       "6712  0.649581  0.395103 -1.023711  ... -0.092033 -0.183593 -0.151182   \n",
       "6713  1.230733 -0.302289 -0.455446  ... -0.092033 -0.183593 -0.151182   \n",
       "\n",
       "           413       414       415       416       417       418       419  \n",
       "0    -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "1    -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "2    -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "3    -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "4    -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6709 -0.162118 -0.177542 -0.199154 -0.177552  5.913007 -0.086772  5.882654  \n",
       "6710 -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "6711 -0.162118 -0.177542 -0.199154  5.947974 -0.169234 -0.086772  6.307612  \n",
       "6712 -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "6713 -0.162118 -0.177542 -0.199154 -0.177552 -0.169234 -0.086772 -0.148134  \n",
       "\n",
       "[6714 rows x 420 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X_TRAIN= pd.DataFrame(scaler.fit_transform(x_train))\n",
    "\n",
    "X_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03a778fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_VALID=scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c346c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09075364,  1.1512305 ,  1.25503131, ..., -0.16923433,\n",
       "        -0.08677224, -0.14813431],\n",
       "       [-0.08632767, -0.48579915, -0.03652868, ..., -0.16923433,\n",
       "        -0.08677224, -0.14813431],\n",
       "       [ 0.36480804,  0.55740602,  0.45644487, ..., -0.16923433,\n",
       "        -0.08677224, -0.14813431],\n",
       "       ...,\n",
       "       [ 0.96070069, -0.48579915,  1.10759996, ..., -0.16923433,\n",
       "        -0.08677224, -0.14813431],\n",
       "       [ 1.43010669, -0.48579915, -0.93954565, ..., -0.16923433,\n",
       "        -0.08677224, -0.14813431],\n",
       "       [-0.9127071 , -0.48579915,  0.5961975 , ..., -0.16923433,\n",
       "        -0.08677224, -0.14813431]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d9c8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier_list = [  MLPClassifier(random_state=1),GradientBoostingClassifier(random_state=1)]\n",
    "def calc_metrics(cf_matrix):\n",
    "  tn = cf_matrix[0]\n",
    "  fp = cf_matrix[1]\n",
    "  fn = cf_matrix[2]\n",
    "  tp = cf_matrix[3]\n",
    "  if (((tp+fn)==0)|((tn+fp)==0)|((tp+fp)==0)|((tn+fp)==0)|((tn+fn)==0)):\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = 0\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = 0\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "  else: \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5)\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b32e8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier_list = [  MLPClassifier(random_state=1),GradientBoostingClassifier(random_state=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d51e05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>470.0</td>\n",
       "      <td>169.4</td>\n",
       "      <td>189.8</td>\n",
       "      <td>513.6</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.751977</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.732497</td>\n",
       "      <td>0.464906</td>\n",
       "      <td>0.723603</td>\n",
       "      <td>0.808109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.707879</td>\n",
       "      <td>0.743560</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.451798</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>0.807122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470.0</td>\n",
       "      <td>169.4</td>\n",
       "      <td>189.8</td>\n",
       "      <td>513.6</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.751977</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.732497</td>\n",
       "      <td>0.464906</td>\n",
       "      <td>0.723603</td>\n",
       "      <td>0.808109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>584.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.707879</td>\n",
       "      <td>0.743560</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.451798</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>0.807122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP     FP     FN     TN      SENS      SPEC      PREC       ACC  \\\n",
       "0  470.0  169.4  189.8  513.6  0.712335  0.751977  0.735437  0.732497   \n",
       "1  584.0  219.0  241.0  635.0  0.707879  0.743560  0.727273  0.726027   \n",
       "2  470.0  169.4  189.8  513.6  0.712335  0.751977  0.735437  0.732497   \n",
       "3  584.0  219.0  241.0  635.0  0.707879  0.743560  0.727273  0.726027   \n",
       "\n",
       "        MCC        F1       AUC  \n",
       "0  0.464906  0.723603  0.808109  \n",
       "1  0.451798  0.717445  0.807122  \n",
       "2  0.464906  0.723603  0.808109  \n",
       "3  0.451798  0.717445  0.807122  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150,500,1000,1500,2000, 3000,4000,5000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,42]\n",
    "}\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = GradientBoostingClassifier(random_state=1)\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(X_TRAIN, y_train):\n",
    "        train_x = X_TRAIN.iloc[train,:]\n",
    "        test_x = X_TRAIN.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(X_VALID)[:,1]\n",
    "    predict_label_y = clf.predict(X_VALID)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf7ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [5000,5500,6000,7000,8000],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,3,4,42]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "clf = ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
    "\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_TRAIN, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred_proba = best_clf.predict_proba(X_VALID)[:, 1]  # predicted probabilities for the positive class\n",
    "auroc = roc_auc_score(y_valid, y_pred_proba)\n",
    "print(\"AUROC on test data: \", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcc3497d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ExtraTreesClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m testing\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_COMP.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m pred\u001b[38;5;241m=\u001b[39m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m aa\u001b[38;5;241m=\u001b[39mpred[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m to_upload \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(aa)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:860\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 860\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1387\u001b[0m     ]\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This ExtraTreesClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "testing= pd.read_csv(\"test_COMP.csv\")\n",
    "pred=clf.predict_proba(testing)\n",
    "aa=pred[:,1]\n",
    "to_upload = pd.DataFrame(aa)\n",
    "cc = [int(10000+i+1) for i in range(len(test))]\n",
    "dd = pd.concat([pd.DataFrame(cc),pd.DataFrame(to_upload)],axis=1)\n",
    "dd.columns = ['ID','Label']\n",
    "dd.to_csv(\"run_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "351ec1ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aa\u001b[38;5;241m=\u001b[39m(\u001b[43mpredict_x\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_x' is not defined"
     ]
    }
   ],
   "source": [
    "aa=(predict_x>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e491e946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maa\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734c384d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m to_upload \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43maa\u001b[49m[:,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      2\u001b[0m cc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test))]\n\u001b[1;32m      3\u001b[0m dd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(cc),pd\u001b[38;5;241m.\u001b[39mDataFrame(to_upload)],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "to_upload = pd.DataFrame(aa[:,1])\n",
    "cc = [1000+i+1 for i in range(len(test))]\n",
    "dd = pd.concat([pd.DataFrame(cc),pd.DataFrame(to_upload)],axis=1)\n",
    "dd.columns = ['ID','Labels']\n",
    "dd.to_csv(\"7_run.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7faa5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv(\"first_run.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e362dbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAC_A</th>\n",
       "      <th>AAC_C</th>\n",
       "      <th>AAC_D</th>\n",
       "      <th>AAC_E</th>\n",
       "      <th>AAC_F</th>\n",
       "      <th>AAC_G</th>\n",
       "      <th>AAC_H</th>\n",
       "      <th>AAC_I</th>\n",
       "      <th>AAC_K</th>\n",
       "      <th>AAC_L</th>\n",
       "      <th>...</th>\n",
       "      <th>DPC1_YM</th>\n",
       "      <th>DPC1_YN</th>\n",
       "      <th>DPC1_YP</th>\n",
       "      <th>DPC1_YQ</th>\n",
       "      <th>DPC1_YR</th>\n",
       "      <th>DPC1_YS</th>\n",
       "      <th>DPC1_YT</th>\n",
       "      <th>DPC1_YV</th>\n",
       "      <th>DPC1_YW</th>\n",
       "      <th>DPC1_YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.11</td>\n",
       "      <td>5.56</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.56</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.04</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.08</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>12.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>26.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>18.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.17</td>\n",
       "      <td>8.33</td>\n",
       "      <td>4.17</td>\n",
       "      <td>12.50</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6714 rows Ã— 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAC_A  AAC_C  AAC_D  AAC_E  AAC_F  AAC_G  AAC_H  AAC_I  AAC_K  AAC_L  \\\n",
       "0     11.11   5.56  11.11  11.11   5.56   5.56   0.00   0.00   0.00   5.56   \n",
       "1      0.00   6.67   0.00  13.33   0.00   0.00   0.00   0.00   0.00   6.67   \n",
       "2     21.74   0.00   0.00  13.04   8.70   8.70   0.00   8.70   4.35   4.35   \n",
       "3      9.09   0.00   0.00   9.09   9.09   0.00   9.09   0.00   9.09   0.00   \n",
       "4      7.69   0.00   0.00  23.08   7.69   0.00   0.00   7.69   7.69   0.00   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "6709   6.25   0.00   6.25  12.50   6.25  12.50   0.00   6.25   0.00   0.00   \n",
       "6710  26.67   0.00   6.67  20.00   0.00   0.00   0.00  13.33  20.00   0.00   \n",
       "6711  13.33   0.00   0.00  20.00   0.00   0.00   0.00   0.00   0.00   6.67   \n",
       "6712  18.18   0.00   0.00   0.00   0.00  18.18   0.00   9.09   9.09   0.00   \n",
       "6713   4.17   0.00  16.67   0.00   4.17   8.33   4.17  12.50   4.17   4.17   \n",
       "\n",
       "      ...  DPC1_YM  DPC1_YN  DPC1_YP  DPC1_YQ  DPC1_YR  DPC1_YS  DPC1_YT  \\\n",
       "0     ...      0.0      0.0     5.88      0.0      0.0      0.0     0.00   \n",
       "1     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "2     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "3     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "4     ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "...   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "6709  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "6710  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "6711  ...      0.0      0.0     0.00      0.0      0.0      0.0     7.14   \n",
       "6712  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "6713  ...      0.0      0.0     0.00      0.0      0.0      0.0     0.00   \n",
       "\n",
       "      DPC1_YV  DPC1_YW  DPC1_YY  \n",
       "0        0.00      0.0     0.00  \n",
       "1        0.00      0.0     0.00  \n",
       "2        0.00      0.0     0.00  \n",
       "3        0.00      0.0     0.00  \n",
       "4        0.00      0.0     0.00  \n",
       "...       ...      ...      ...  \n",
       "6709     6.67      0.0     6.67  \n",
       "6710     0.00      0.0     0.00  \n",
       "6711     0.00      0.0     7.14  \n",
       "6712     0.00      0.0     0.00  \n",
       "6713     0.00      0.0     0.00  \n",
       "\n",
       "[6714 rows x 420 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d78baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold #Import the library\n",
    "sel = VarianceThreshold(1.0) # This will remove all zero-variance features\n",
    "sf = sel.fit_transform(X_TRAIN) # The file will be saved in sf\n",
    "sc = X_TRAIN.columns[sel.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "x2=X_TRAIN[sc] #This will show the first few rows of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1a7efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>22</th>\n",
       "      <th>27</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>33</th>\n",
       "      <th>...</th>\n",
       "      <th>396</th>\n",
       "      <th>399</th>\n",
       "      <th>405</th>\n",
       "      <th>407</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>413</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>418</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788975</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>1.597940</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>7.982345</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.043471</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>1.770411</td>\n",
       "      <td>0.155586</td>\n",
       "      <td>0.672518</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>5.552724</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.583114</td>\n",
       "      <td>0.216851</td>\n",
       "      <td>0.483565</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>7.597072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.410984</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>0.320383</td>\n",
       "      <td>0.885115</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.165571</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>0.087729</td>\n",
       "      <td>3.190332</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>5.000529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>1.372187</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>4.467796</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>3.450867</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>5.552724</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>5.947974</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.649581</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>1.176915</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>10.357637</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>1.230733</td>\n",
       "      <td>0.165982</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6714 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         7         15        17        19        22        27   \\\n",
       "0     0.788975 -0.899591 -0.979253 -0.922056  1.597940 -0.214149 -0.225527   \n",
       "1     1.043471 -0.899591  1.770411  0.155586  0.672518 -0.214149 -0.225527   \n",
       "2    -0.485799  0.583114  0.216851  0.483565 -0.717698 -0.214149 -0.225527   \n",
       "3    -0.485799 -0.899591 -0.979253 -0.922056 -0.717698 -0.214149 -0.225527   \n",
       "4    -0.485799  0.410984 -0.979253  0.320383  0.885115 -0.214149 -0.225527   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6709 -0.485799  0.165571 -0.979253  0.087729  3.190332 -0.214149 -0.225527   \n",
       "6710 -0.485799  1.372187 -0.062240 -0.922056 -0.717698 -0.214149  4.467796   \n",
       "6711 -0.485799 -0.899591 -0.979253 -0.922056  3.450867 -0.214149 -0.225527   \n",
       "6712 -0.485799  0.649581 -0.979253 -0.922056  1.176915 -0.214149 -0.225527   \n",
       "6713 -0.485799  1.230733  0.165982 -0.922056 -0.717698 -0.214149 -0.225527   \n",
       "\n",
       "            30        31        33   ...       396       399       405  \\\n",
       "0     -0.137758  7.982345 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "1     -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "2     -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "3     -0.137758 -0.202328  7.597072  ... -0.121308 -0.092356 -0.180788   \n",
       "4     -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "6709  -0.137758 -0.202328  5.000529  ... -0.121308 -0.092356 -0.180788   \n",
       "6710  -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "6711  -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "6712  10.357637 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "6713  -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "\n",
       "           407       409       410       413       415       416       418  \n",
       "0    -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "1    -0.161306  5.552724 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "2    -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "3    -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "4    -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6709 -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "6710 -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "6711 -0.161306  5.552724 -0.092033 -0.162118 -0.199154  5.947974 -0.086772  \n",
       "6712 -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "6713 -0.161306 -0.186030 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "\n",
       "[6714 rows x 138 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c42532e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val= sel.transform(X_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42ff4c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_val=pd.DataFrame(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdab916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.151231</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>0.770480</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>6.419828</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.102513</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.557406</td>\n",
       "      <td>-0.124153</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>1.281699</td>\n",
       "      <td>0.230651</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>5.847540</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.047977</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>0.872938</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>1.535796</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.124153</td>\n",
       "      <td>0.270469</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>0.985382</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>1.372187</td>\n",
       "      <td>-0.979253</td>\n",
       "      <td>0.155586</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>-0.899591</td>\n",
       "      <td>0.165982</td>\n",
       "      <td>-0.922056</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>-0.485799</td>\n",
       "      <td>0.804668</td>\n",
       "      <td>-0.291837</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>-0.717698</td>\n",
       "      <td>-0.214149</td>\n",
       "      <td>-0.225527</td>\n",
       "      <td>-0.137758</td>\n",
       "      <td>-0.202328</td>\n",
       "      <td>-0.200356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121308</td>\n",
       "      <td>-0.092356</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>-0.161306</td>\n",
       "      <td>-0.18603</td>\n",
       "      <td>-0.092033</td>\n",
       "      <td>-0.162118</td>\n",
       "      <td>-0.199154</td>\n",
       "      <td>-0.177552</td>\n",
       "      <td>-0.086772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1679 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     1.151231 -0.899591 -0.979253 -0.922056  0.770480 -0.214149 -0.225527   \n",
       "1    -0.485799  0.102513 -0.979253  0.027950 -0.717698 -0.214149 -0.225527   \n",
       "2     0.557406 -0.124153 -0.979253  1.281699  0.230651 -0.214149 -0.225527   \n",
       "3    -0.485799  0.047977 -0.979253  0.872938 -0.717698 -0.214149 -0.225527   \n",
       "4    -0.485799  1.535796  0.002377 -0.922056 -0.717698 -0.214149 -0.225527   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1674 -0.485799 -0.124153  0.270469 -0.922056 -0.717698 -0.214149 -0.225527   \n",
       "1675 -0.485799 -0.899591  0.985382  0.231522 -0.717698 -0.214149 -0.225527   \n",
       "1676 -0.485799  1.372187 -0.979253  0.155586 -0.717698 -0.214149 -0.225527   \n",
       "1677 -0.485799 -0.899591  0.165982 -0.922056 -0.717698 -0.214149 -0.225527   \n",
       "1678 -0.485799  0.804668 -0.291837  0.693600 -0.717698 -0.214149 -0.225527   \n",
       "\n",
       "           7         8         9    ...       128       129       130  \\\n",
       "0    -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "1    -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "2    -0.137758 -0.202328 -0.200356  ...  5.847540 -0.092356 -0.180788   \n",
       "3    -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "4    -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1674 -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "1675 -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "1676 -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "1677 -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "1678 -0.137758 -0.202328 -0.200356  ... -0.121308 -0.092356 -0.180788   \n",
       "\n",
       "           131      132       133       134       135       136       137  \n",
       "0    -0.161306 -0.18603 -0.092033 -0.162118 -0.199154  6.419828 -0.086772  \n",
       "1    -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "2    -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "3    -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "4    -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "...        ...      ...       ...       ...       ...       ...       ...  \n",
       "1674 -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "1675 -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "1676 -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "1677 -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "1678 -0.161306 -0.18603 -0.092033 -0.162118 -0.199154 -0.177552 -0.086772  \n",
       "\n",
       "[1679 rows x 138 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7b27529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478.2</td>\n",
       "      <td>180.4</td>\n",
       "      <td>181.6</td>\n",
       "      <td>502.6</td>\n",
       "      <td>0.724765</td>\n",
       "      <td>0.735871</td>\n",
       "      <td>0.726423</td>\n",
       "      <td>0.730414</td>\n",
       "      <td>0.460871</td>\n",
       "      <td>0.725417</td>\n",
       "      <td>0.791752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>609.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.738182</td>\n",
       "      <td>0.759953</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>0.749256</td>\n",
       "      <td>0.498291</td>\n",
       "      <td>0.743136</td>\n",
       "      <td>0.807440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452.0</td>\n",
       "      <td>196.2</td>\n",
       "      <td>207.8</td>\n",
       "      <td>486.8</td>\n",
       "      <td>0.685049</td>\n",
       "      <td>0.712738</td>\n",
       "      <td>0.697590</td>\n",
       "      <td>0.699131</td>\n",
       "      <td>0.398042</td>\n",
       "      <td>0.691204</td>\n",
       "      <td>0.766356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.688485</td>\n",
       "      <td>0.725995</td>\n",
       "      <td>0.708229</td>\n",
       "      <td>0.707564</td>\n",
       "      <td>0.414832</td>\n",
       "      <td>0.698218</td>\n",
       "      <td>0.770962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP     FP     FN     TN      SENS      SPEC      PREC       ACC  \\\n",
       "0  478.2  180.4  181.6  502.6  0.724765  0.735871  0.726423  0.730414   \n",
       "1  609.0  205.0  216.0  649.0  0.738182  0.759953  0.748157  0.749256   \n",
       "2  452.0  196.2  207.8  486.8  0.685049  0.712738  0.697590  0.699131   \n",
       "3  568.0  234.0  257.0  620.0  0.688485  0.725995  0.708229  0.707564   \n",
       "\n",
       "        MCC        F1       AUC  \n",
       "0  0.460871  0.725417  0.791752  \n",
       "1  0.498291  0.743136  0.807440  \n",
       "2  0.398042  0.691204  0.766356  \n",
       "3  0.414832  0.698218  0.770962  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    cv = LeaveOneOut()\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x2, y_train):\n",
    "        train_x = x2.iloc[train,:]\n",
    "        test_x = x2.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_val)[:,1]\n",
    "    predict_label_y = clf.predict(x_val)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bcc9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3a9119d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6714, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "x = x_train\n",
    "y= x_valid\n",
    "x_train_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(x)\n",
    "x_train_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c76241a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_valid_embedded = TSNE(n_components=3,).fit_transform(y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06d691b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_tsne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x_valid_embedded\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(x_valid_embedded)\n\u001b[1;32m      2\u001b[0m x_train_embedded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(x_train_embedded)\n\u001b[0;32m----> 3\u001b[0m test_tsne\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtest_tsne\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_tsne' is not defined"
     ]
    }
   ],
   "source": [
    "x_valid_embedded=pd.DataFrame(x_valid_embedded)\n",
    "x_train_embedded = pd.DataFrame(x_train_embedded)\n",
    "test_tsne=pd.DataFrame(test_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0ba673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>425.2</td>\n",
       "      <td>220.2</td>\n",
       "      <td>234.6</td>\n",
       "      <td>462.8</td>\n",
       "      <td>0.644438</td>\n",
       "      <td>0.677599</td>\n",
       "      <td>0.659331</td>\n",
       "      <td>0.661306</td>\n",
       "      <td>0.323512</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.714016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.372365</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>0.503871</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>0.559026</td>\n",
       "      <td>0.500118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>427.6</td>\n",
       "      <td>189.8</td>\n",
       "      <td>232.2</td>\n",
       "      <td>493.2</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.722108</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.685732</td>\n",
       "      <td>0.371346</td>\n",
       "      <td>0.669514</td>\n",
       "      <td>0.742231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.627879</td>\n",
       "      <td>0.368852</td>\n",
       "      <td>0.490066</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>0.550478</td>\n",
       "      <td>0.517270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP     FP     FN     TN      SENS      SPEC      PREC       ACC  \\\n",
       "0  425.2  220.2  234.6  462.8  0.644438  0.677599  0.659331  0.661306   \n",
       "1  528.0  536.0  297.0  318.0  0.640000  0.372365  0.496241  0.503871   \n",
       "2  427.6  189.8  232.2  493.2  0.648077  0.722108  0.692488  0.685732   \n",
       "3  518.0  539.0  307.0  315.0  0.627879  0.368852  0.490066  0.496129   \n",
       "\n",
       "        MCC        F1       AUC  \n",
       "0  0.323512  0.650369  0.714016  \n",
       "1  0.012831  0.559026  0.500118  \n",
       "2  0.371346  0.669514  0.742231  \n",
       "3 -0.003384  0.550478  0.517270  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train_embedded, y_train):\n",
    "        train_x = x_train_embedded.iloc[train,:]\n",
    "        test_x = x_train_embedded.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_valid_embedded)[:,1]\n",
    "    predict_label_y = clf.predict(x_valid_embedded)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "435f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Load your gene expression data\n",
    "\n",
    "\n",
    "# Create a Lasso object with the desired alpha value\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the Lasso model to your data\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# Get the coefficients of the fitted model\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Get the indices of the nonzero coefficients\n",
    "selected_indices = np.where(coefficients != 0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "721ef60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    2,    4, ..., 6710, 6711, 6712])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bad997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd462155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25e84c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4a77186",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m cv \u001b[38;5;241m=\u001b[39m LeaveOneOut()\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cross_val_predict(model, x_train, y_train, cv\u001b[38;5;241m=\u001b[39mcv, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m auroc_score \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauroc_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:580\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    574\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_base.py:72\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous-multioutput format is not supported"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "y_pred = cross_val_predict(model, x_train, y_train, cv=cv, method='predict_proba')\n",
    "\n",
    "auroc_score = roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "print(f\"AUROC score: {auroc_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a1a480d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [52], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m train_y \u001b[38;5;241m=\u001b[39m y_train[train]\n\u001b[1;32m     11\u001b[0m test_y \u001b[38;5;241m=\u001b[39m y_train[test]\n\u001b[0;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(train_X, train_y)\n\u001b[1;32m     13\u001b[0m predict_y \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(test_X)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m auc_scores\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(test_y, predict_y))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "cv = LeaveOneOut()\n",
    "clf = i\n",
    "auc_scores=[]\n",
    "for train, test in skf.split(x_train, y_train):\n",
    "    train_X = x_train.iloc[train,:]\n",
    "    test_X = x_train.iloc[test]\n",
    "    train_y = y_train[train]\n",
    "    test_y = y_train[test]\n",
    "    clf.fit(train_X, train_y)\n",
    "    predict_y = clf.predict_proba(test_X)[:,1]\n",
    "    auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "np.array(auc_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d5cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
