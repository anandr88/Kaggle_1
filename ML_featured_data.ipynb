{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd37c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import getopt\n",
    "import collections\n",
    "import tqdm\n",
    "import itertools\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from scipy import stats\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import xgboost\n",
    "\n",
    "def calc_metrics(cf_matrix):\n",
    "  tn = cf_matrix[0]\n",
    "  fp = cf_matrix[1]\n",
    "  fn = cf_matrix[2]\n",
    "  tp = cf_matrix[3]\n",
    "  if (((tp+fn)==0)|((tn+fp)==0)|((tp+fp)==0)|((tn+fp)==0)|((tn+fn)==0)):\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = 0\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = 0\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "  else: \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5)\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bd660eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing= pd.read_csv(\"testing_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a057913",
   "metadata": {},
   "outputs": [],
   "source": [
    "te= pd.read_csv(\"x_test_filtered.csv\")\n",
    "tr= pd.read_csv(\"x_train_filtered.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cabec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e69bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tr.drop(columns=['Label'])\n",
    "y_train = tr.Label\n",
    "x_test = te.drop(columns=['Label'])\n",
    "y_test = te.Label\n",
    "\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "x_test.reset_index(inplace=True, drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "303788f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = [ExtraTreesClassifier(random_state=1, n_jobs= -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78d0cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(n_jobs=-1, random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547.4</td>\n",
       "      <td>128.0</td>\n",
       "      <td>112.4</td>\n",
       "      <td>555.0</td>\n",
       "      <td>0.829649</td>\n",
       "      <td>0.812592</td>\n",
       "      <td>0.810480</td>\n",
       "      <td>0.820974</td>\n",
       "      <td>0.642272</td>\n",
       "      <td>0.819884</td>\n",
       "      <td>0.905864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>0.846061</td>\n",
       "      <td>0.809133</td>\n",
       "      <td>0.810685</td>\n",
       "      <td>0.827278</td>\n",
       "      <td>0.655311</td>\n",
       "      <td>0.827995</td>\n",
       "      <td>0.916144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP     FP     FN     TN      SENS      SPEC      PREC       ACC  \\\n",
       "0  547.4  128.0  112.4  555.0  0.829649  0.812592  0.810480  0.820974   \n",
       "1  698.0  163.0  127.0  691.0  0.846061  0.809133  0.810685  0.827278   \n",
       "\n",
       "        MCC        F1       AUC  \n",
       "0  0.642272  0.819884  0.905864  \n",
       "1  0.655311  0.827995  0.916144  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train, y_train):\n",
    "        train_x = x_train.iloc[train,:]\n",
    "        test_x = x_train.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean())\n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_test)[:,1]\n",
    "    predict_label_y = clf.predict(x_test)\n",
    "    test_auc = roc_auc_score(y_test, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_test,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c011ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of the columns on the basis of mean and standard deviation ((x-u)/s)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "#PCA(reduce dimention of feture)\n",
    "#Imputer(handel nan values)\n",
    "\n",
    "#for train use fit.transform function\n",
    "#x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "#x1.columns=x.columns\n",
    "#x1\n",
    "#for test data just .transform function\n",
    "#x_test_scaled=pd.DataFrame(scaler.transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(scaler.transform(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "546d9615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(n_jobs=-1, random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547.4</td>\n",
       "      <td>128.0</td>\n",
       "      <td>112.4</td>\n",
       "      <td>555.0</td>\n",
       "      <td>0.829649</td>\n",
       "      <td>0.812592</td>\n",
       "      <td>0.810480</td>\n",
       "      <td>0.820974</td>\n",
       "      <td>0.642272</td>\n",
       "      <td>0.819884</td>\n",
       "      <td>0.905864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>0.846061</td>\n",
       "      <td>0.809133</td>\n",
       "      <td>0.810685</td>\n",
       "      <td>0.827278</td>\n",
       "      <td>0.655311</td>\n",
       "      <td>0.827995</td>\n",
       "      <td>0.916144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP     FP     FN     TN      SENS      SPEC      PREC       ACC  \\\n",
       "0  547.4  128.0  112.4  555.0  0.829649  0.812592  0.810480  0.820974   \n",
       "1  698.0  163.0  127.0  691.0  0.846061  0.809133  0.810685  0.827278   \n",
       "\n",
       "        MCC        F1       AUC  \n",
       "0  0.642272  0.819884  0.905864  \n",
       "1  0.655311  0.827995  0.916144  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train_scaled, y_train):\n",
    "        train_x = x_train_scaled.iloc[train,:]\n",
    "        test_x = x_train_scaled.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean())\n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_test_scaled)[:,1]\n",
    "    predict_label_y = clf.predict(x_test_scaled)\n",
    "    test_auc = roc_auc_score(y_test, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_test,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ec1ff8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'n_estimators': 7000, 'random_state': 1}\n",
      "AUROC on test data:  0.939146263572493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [7000],\n",
    "\n",
    "    'random_state': [1]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "clf = ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
    "\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred_proba = best_clf.predict_proba(x_test)[:, 1]  # predicted probabilities for the positive class\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUROC on test data: \", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "abe2fcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32514286, 0.50871429, 0.        , ..., 0.688     , 1.        ,\n",
       "       0.836     ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4982793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=(y_pred_proba>0.53).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7ce4db7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5389d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8558665872543181"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "\n",
    "accuracy = accuracy_score(y_test, aa)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c729eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_pred_proba = best_clf.predict_proba(testing)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "62b18f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab=(testing_pred_proba>0.53).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "05efccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(ab)\n",
    "df.columns = ['Label']\n",
    "ID = np.arange(1598) + 10001\n",
    "ID = pd.DataFrame(ID)\n",
    "ID.columns = ['ID']\n",
    "final_data = pd.concat([ID, df], axis=1)\n",
    "final_data.to_csv('run_14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5a338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
